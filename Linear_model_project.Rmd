---
title: "Линейная модель средней стоимости домов в Бостоне"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Общая структура данных

В данной работе проводится построение линейной модели средней стоимости домов (в 1000 долларов) в Бостоне в 1970-1980-х годах на основе данных *Boston*, встроенных в пакет **MASS**. Библиотеки, которые необходимы для выполнения данного проекта **ggplot2**, **dplyr**, **lmtest**, **car**, **gridExtra** и, конечно, **MASS**:

```{r, echo=TRUE, include=FALSE, warning=FALSE}

check.packages <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    if (length(new.pkg)) 
        install.packages(new.pkg, dependencies = TRUE)
    sapply(pkg, require, character.only = TRUE)
}
packages<-c("ggplot2", "dplyr", "lmtest", "car", "gridExtra","MASS")
check.packages(packages)
```

Для начала посмотрим на структуру данных:
```{r}
str(Boston)
```

Переменная *medv* -- это как раз средняя стоимость домов в тыс.долларов, *crim* -- уровень преступности на душу населения, *zn* -- доля жилой земли на участке, *indus* -- доля площадей супермаркетов на город,  *chas* -- близость к реке (1 -- рядом, 0 -- далеко), *nox* -- концентрация оксидов азота, *rm* -- среднее количество комнат в доме, *age* -- доля старых (до 1940 года) построек, *dis* -- средневзвешенное расстояние до 5 бостонских центров занятости, *rad* -- индекс доступности к радиальным магистралям, *tax* -- налог, *ptratio* -- соотношение ученика-учителя, *black* - доля чернокожих, *lstat* -- процент малообеспеченных слоев населения.

## 1. Полная линейная модель

Для удобства анализа коэффициентов перед предикторами стандартизуем их:
```{r}
data <- as.data.frame(sapply(Boston, scale))
```

Построим полную модель.
```{r}
model_full <- lm(medv ~ ., data)
summary(model_full)
```

Рассматривая коэффициенты перед предикторами, можно сделать вывод, что во-первых, значимо наибольший вклад в стоимость вносит коэффициент *lstat*, что очевидно: чем менее благополучные люди живут вокруг, тем в меньшем достатке они находятся, что явно указывает на то, что и жилье рядом будет стоить дешевле, и наоборот (поэтому и коэффициент отрицательный). Несильно отстает по величине вклада предиктор будет *dis* -- также понятно почему: вокруг центров занятости живут люди на пособие по безработице, а значит не очень высокого достатка. Почти одинаковый вклад вносят *rm*, *nox*, *tax* и *ptratio*, а за ними по величине вклада *crim*, *zn* и *black*. Заметим, что предикторы *indus* (доля площадей торговых точек), *age* (доля построек до 1940г.) незначимо влияют на значение средней стоимости домов. Этот факт мы будем использовать при редукции нашей модели. Но для начала проведем диагностику полной модели.

### 1.1 Диагностика полной модели

Во-первых, при построении модели в результатах мы можем увидеть значение F-критерия, при помощи которого проверяется гипотеза об отсутствии связи между зависимой переменной и предикторами. Мы получили, что значение F-критерия значимо много больше 1. Это значит, что вероятность получить случайно такое значение связи между предсказываемой величиной и предикторами очень мала, а значит модель в целом должна хорошо описывать наши данные. Также важно посмотреть на скорректированный коэффициент детерминации, в случае полной модели он равен 0.7338, то есть это означает, что наша модель объясняет около 73% дисперсии предсказываемой переменной.

Построим график остатков:

```{r}
model_full_diag <- data.frame(fortify(model_full), data[])

gg_full <- ggplot(data = model_full_diag, aes(x = .fitted, y = .stdresid)) + 
  geom_point() + 
  geom_hline(yintercept = 0) +
  geom_smooth(method = "lm") +
  geom_hline(yintercept = 2, color = "red") +
  geom_hline(yintercept = -2, color = "red")
gg_full
```

Остатки в левой и правой части графика имеют в основном только положительные значения, а посередине -- отрицательные, что говорит о том, что на самом деле взаимосвязь между предсказываемой переменной и предикторами **не линейна**. Также по графику остатков видно, что в целом, наша модель **гетероскедастична**, то есть ошибки в различных наблюдениях немного скоррелированы. Проверим теперь данный факт численно, применив тест Бройша-Пагана (в более общей формулировке без требования нормальности остатков):

```{r}
bptest(model_full)
```

Таким образом, мы отвергаем гипотезу о гомоскедастичности остатков модели. Также по графику остатков можно сделать вывод, что наблюдается какая-то автокорреляция -- то есть **наблюдения на самом деле не будут независимыми**. 


Построим график Кука:

```{r}
ggplot(model_full_diag, aes(x = 1:nrow(model_full_diag), y = .cooksd)) + 
  geom_bar(stat = "identity") + 
  geom_hline(yintercept = 2, color = "red")
```

По этому графику можно сделать вывод, что **влиятельных наблюдений в нашем датасете нет**.

Чтобы проверить распределение на нормальность, будем использовать остатки, так как если начальное распределение распределено нормально, то остатки также должны быть распределены нормально. Построим квантильный график остатков (по оси y стьюдентизированные остатки, а по оси х -- квантили t-распределения). 

```{r}
qqPlot(model_full_diag$.stdresid)
```

Так как точки не легли на одну прямую, то это означает, что остатки **не подчиняются нормальному распределению** (есть хвосты), а **дисперсия непостоянна**.

По совокупности полученных результатов, можем сделать вывод, что несмотря на то, что в целом модель хорошо объясняет дисперсию наблюдений, возможно, нам стоит рассматривать нелинейные модели. 

### 1.3 График предсказаний стоимости от процента малоимущих

```{r}
ggplot(data, aes(x = lstat, y = medv)) + 
  geom_point() + 
  geom_smooth(method = 'lm') 
```

## 2. Поиск оптимальной модели и ее исследование

### 2.1 Удаление коллинеарных предикторов

Одно из важнейших требований к предикторам при построении линейной модели является отсутствие мультиколлинеарности. Чтобы соблюсти это требование, будем рассматривать значения VIF для каждого предиктора в модели. 

```{r}
vif(model_full)
```

У нас есть некоторые предикторы, для которых VIF > 2, что является не очень хорошим знаком -- эти предикторы могут портить модель, потому что они коллинерны другим предикторам. Будем их исключать по одному, выбирая максимальный, пока не останутся предикторы со значением VIF < 2.

```{r}
model_1 <- update(model_full, .~. - tax)
vif(model_1)
```
```{r}
model_2 <- update(model_1, .~. - nox)
vif(model_2)
```
```{r}
model_3 <- update(model_2, .~. - dis)
vif(model_3)
```
```{r}
model_4 <- update(model_3, .~. - lstat)
vif(model_4)
```
```{r}
model_5 <- update(model_4, .~. - rad)
vif(model_5)
```
```{r}
model_6 <- update(model_5, .~. - indus)
vif(model_6)
```

Судя по VIF у нас не осталось явно кореллирующих предикторов, поэтому посмотрим на получившуюся модель:

```{r}
summary(model_6)
```

Чтобы понять, не удалили ли мы значимые предикторы, рассмотрим график остатков:

```{r}
model_6_diag <- data.frame(fortify(model_6), data[])

gg_resid <- ggplot(data = model_6_diag, aes(x = .fitted, y = .stdresid)) + 
  geom_point() + 
  geom_hline(yintercept = 0) +
  geom_smooth(method = "lm") +
  geom_hline(yintercept = 2, color = "red") +
  geom_hline(yintercept = -2, color = "red")

res_1 <- gg_resid + aes(x = tax)
res_2 <- gg_resid + aes(x = nox)
res_3 <- gg_resid + aes(x = dis)
res_4 <- gg_resid + aes(x = lstat)
res_5 <- gg_resid + aes(x = rad)
res_6 <- gg_resid + aes(x = indus)

grid.arrange(res_1, res_2, res_3, res_4, res_5, res_6, nrow = 2)
```

Судя по графикам, нам стоит вернуть переменные *dis* и *lstat*:

```{r}
model_6 <- update(model_6, .~. + dis + lstat)
```

### 2.2 Отбор предикторов по значимости

Для отбора предикторов будем рассматривать их значимость при помощи F-теста и функции *drop1*.

```{r}
drop1(model_6, test = "F")
```

Из результата работы функции можно понять, что удаление предиктора *age* незначимо влияет на объясняемую изменчивость модели. Удалим его и повторим процедуру.

```{r}
model_7 <- update(model_6, .~. - age)
drop1(model_7, test = "F")
```

Также поступим и с предиктором *crim*:
```{r}
model_8 <- update(model_7, .~. - crim)
drop1(model_8, test = "F")
```

Аналогично с  *zn*:
```{r}
model_9 <- update(model_8, .~. - zn)
drop1(model_9, test = "F")
```
Больше не осталось предикторов, удаление которых было бы незначимо для данной модели. 

```{r}
summary(model_9)
```

### 2.3 Диагностика редуцированной модели

Построим график остатков полученной модели:

```{r}
model_9_diag <- data.frame(fortify(model_9), data[])

gg_resid <- ggplot(data = model_9_diag, aes(x = .fitted, y = .stdresid)) + 
  geom_point() + 
  geom_hline(yintercept = 0) +
  geom_smooth(method = "lm") +
  geom_hline(yintercept = 2, color = "red") +
  geom_hline(yintercept = -2, color = "red")
gg_resid
```

Во-первых, сразу, как и в случае полной модели, можно сказать, что взаимосвязь **нелинейная**. Во-вторых, остатки **гетероскедастичны**:

```{r}
bptest(model_9)
```

В-третьих, мы также видим, что наблюдения на самом деле **не являются независимыми**. 

Построим график остатков Кука:

```{r}
ggplot(model_9_diag, aes(x = 1:nrow(model_9_diag), y = .cooksd)) + 
  geom_bar(stat = "identity") + 
  geom_hline(yintercept = 2, color = "red")
```

По этому графику можно сделать вывод, что **влиятельных наблюдений в нашем датасете нет**.

Построим квантильный график остатков (по оси y стьюдентизированные остатки, а по оси х -- квантили t-распределения). 

```{r}
qqPlot(model_9_diag$.stdresid)
```

Так как точки не легли на одну прямую, то это означает, что остатки **не подчиняются нормальному распределению** (есть хвосты), а **дисперсия непостоянна**.


### 2.4 Обсуждение

В целом, наша модель не улучшилась по сравнению с полной по показателю коэффициента детерминации, но зато критерий F-статистики вырос, а самое главное, анализировать такую модель стало гораздо проще: предикторы практически не коррелируют, а также нет никаких незначимых предикторов.

```{r}
summary(model_9)
```

Итоговая модель: **medv = -0.02046 + 0.29585 \* chas + 0.33648 \* rm - 0.213 \* ptratio + 0.11445 \* black - 0.12762 \* dis - 0.46893 \* lstat**.
Здесь интерсепт, конечно, не несет никакого смысла. Согласно модели, на стоимость квартир в Бостоне в 1970-80 годах влияли следующие показатели в порядке убывания их вклада: *lstat* -- процент малоимущих, живущих неподалеку (связь отрицательная), *rm* -- количество комнат в квартире (чем больше, тем, соответственно дороже), *chas* -- близость к реке, *ptratio* -- соотношение ученик-учитель (связь отрицательная, что также понятно -- это является довольно важным фактором для родителей, которые хотят для своего ребенка лучшее образование), *dis* -- близость к центрам занятости населения также отрицательно сказывается на стоимости жилья, *black* -- а вот доля чернокожего населения  

Наибольший вклад в среднюю стоимость жилья в Бостоне вносит значение доли малоимущих неподалеку. Построим проекцию построенной многомерной плоскости на ось *lstat* (а также на ось *rm*):
```{r}
ggplot(data, aes(x = lstat, y = medv)) + 
  geom_point() + 
  geom_smooth(method = "lm") 
```
```{r}
ggplot(data, aes(x = rm, y = medv)) + 
  geom_point() + 
  geom_smooth(method = "lm") 
```


### 3. Построение новой модели

Заметим, что при диагностике моделей мы постоянно натыкались на проблему нелинейности. Попробуем ее решить следующим образом -- введем новую переменную: корень квадратный из количества комнат.  
```{r}
data$lstat2 <- 1 / (data$lstat)
model_10 <- lm(medv ~ chas + rm + ptratio + black + dis + lstat2, data)
summary(model_9)
summary(model_10)
```